{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/divyanshu/Desktop/Kaggle/Facial_Expressions/fer13/fer2013/fer2013.csv\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "BASE_PATH = \"/home/divyanshu/Desktop/Kaggle/Facial_Expressions/fer13\"\n",
    "INPUT_PATH = path.sep.join([BASE_PATH,\"fer2013/fer2013.csv\"])\n",
    "print(INPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/divyanshu/Desktop/Kaggle/Facial_Expressions/fer13/hdf5/train.hdf5\n"
     ]
    }
   ],
   "source": [
    "n_classes = 7\n",
    "TRAIN_HDF5 = path.sep.join([BASE_PATH, \"hdf5/train.hdf5\"])\n",
    "print(TRAIN_HDF5)\n",
    "VAL_HDF5 = path.sep.join([BASE_PATH, \"hdf5/val.hdf5\"])\n",
    "TEST_HDF5 = path.sep.join([BASE_PATH, \"hdf5/test.hdf5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "OUTPUT_PATH = path.sep.join([BASE_PATH, \"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdf5datasetwriter import HDF5DatasetWriter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(INPUT_PATH)\n",
    "f.__next__()\n",
    "(trainImages, trainLabels) = ([], [])\n",
    "(valImages, valLabels) = ([], [])\n",
    "(testImages, testLabels) = ([], [])\n",
    "labels = []\n",
    "imlist = []\n",
    "for row in f:\n",
    "    (label, image, usage) = row.strip().split(\",\")\n",
    "    label = int(label)\n",
    "    image = np.array(image.split(\" \"), dtype = \"uint8\")\n",
    "    image = image.reshape((1, 48, 48, 1))\n",
    "    if usage == \"Training\":\n",
    "        trainImages.append(image)\n",
    "        trainLabels.append(label)\n",
    "    elif usage == \"PrivateTest\":\n",
    "        valImages.append(image)\n",
    "        valLabels.append(label)\n",
    "    else:\n",
    "        testImages.append(image)\n",
    "        testLabels.append(label)\n",
    "datasets = [\n",
    "(trainImages, trainLabels, TRAIN_HDF5),\n",
    "(valImages, valLabels, VAL_HDF5),\n",
    "(testImages, testLabels, TEST_HDF5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 1, 48, 48, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(trainImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Path already exists. Manually delete it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7b6638375344>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputPath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHDF5DatasetWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Kaggle/Facial_Expressions/hdf5datasetwriter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dims, outputPath, dataKey, bufSize)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataKey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"images\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Path already exists. Manually delete it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataKey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Path already exists. Manually delete it"
     ]
    }
   ],
   "source": [
    "for (images, labels, outputPath) in datasets:\n",
    "    writer = HDF5DatasetWriter((len(images), 48, 48, 1), outputPath)\n",
    "    for (image, label) in zip(images, labels):\n",
    "        writer.add([image], [label])\n",
    "    writer.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", input_shape=(48,48,1)))\n",
    "#model.add(ELU())\n",
    "#model.add(BatchNormalization(axis=-1))\n",
    "#model.add(Conv2D(32, (3, 3), kernel_initializer=\"he_normal\",\n",
    "#padding=\"same\"))\n",
    "#model.add(ELU())\n",
    "#model.add(BatchNormalization(axis=-1))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(Conv2D(64, (3, 3), kernel_initializer=\"he_normal\",\n",
    "#padding=\"same\"))\n",
    "#model.add(ELU())\n",
    "#model.add(BatchNormalization(axis=-1))\n",
    "#model.add(Conv2D(64, (3, 3), kernel_initializer=\"he_normal\",\n",
    "#padding=\"same\"))\n",
    "#model.add(ELU())\n",
    "#model.add(BatchNormalization(axis=-1))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(Conv2D(128, (3, 3), kernel_initializer=\"he_normal\",\n",
    "#padding=\"same\"))\n",
    "#model.add(ELU())\n",
    "#model.add(BatchNormalization(axis=-1))\n",
    "#model.add(Conv2D(128, (3, 3), kernel_initializer=\"he_normal\",\n",
    "#padding=\"same\"))\n",
    "#model.add(ELU())\n",
    "#model.add(BatchNormalization(axis=-1))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(64, kernel_initializer=\"he_normal\"))\n",
    "#model.add(ELU())\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(64, kernel_initializer=\"he_normal\"))\n",
    "#model.add(ELU())\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(n_classes, kernel_initializer=\"he_normal\", activation=\"softmax\"))\n",
    "opt = Adam(lr=1e-3)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagetoarray_preprocessor import ImageToArrayPreprocessor\n",
    "from trainingmonitor import TrainingMonitor\n",
    "from hdf5datasetgenerator import HDF5DatasetGenerator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAug = ImageDataGenerator(rotation_range=10, zoom_range=0.1,\n",
    "horizontal_flip=True, rescale=1 / 255.0, fill_mode=\"nearest\")\n",
    "valAug = ImageDataGenerator(rescale=1 / 255.0)\n",
    "iap = ImageToArrayPreprocessor()\n",
    "trainGen = HDF5DatasetGenerator(TRAIN_HDF5, BATCH_SIZE,\n",
    "aug=trainAug, preprocessors=[iap], classes=n_classes)\n",
    "valGen = HDF5DatasetGenerator(VAL_HDF5, BATCH_SIZE,\n",
    "aug=valAug, preprocessors=[iap], classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "import os\n",
    "\n",
    "class EpochCheckpoint(Callback):\n",
    "    def __init__(self, outputPath, every=5, startAt=0):\n",
    "        # call the parent constructor\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        # store the base output path for the model, the number of\n",
    "        # epochs that must pass before the model is serialized to\n",
    "        # disk and the current epoch value\n",
    "        self.outputPath = outputPath\n",
    "        self.every = every\n",
    "        self.intEpoch = startAt\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # check to see if the model should be serialized to disk\n",
    "        if (self.intEpoch + 1) % self.every == 0:\n",
    "            p = os.path.sep.join([self.outputPath,\"epoch_{}.hdf5\".format(self.intEpoch + 1)])\n",
    "            self.model.save(p, overwrite=True)\n",
    "\n",
    "        # increment the internal epoch counter\n",
    "        self.intEpoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figPath = os.path.sep.join([OUTPUT_PATH,\n",
    "\"vggnet_emotion.png\"])\n",
    "jsonPath = os.path.sep.join([OUTPUT_PATH,\n",
    "\"vggnet_emotion.json\"])\n",
    "#callbacks = [\n",
    "# EpochCheckpoint(\"/home/divyanshu/Desktop/Kaggle/Facial_Expressions/checkpoints\", every=5,startAt=0),\n",
    "# TrainingMonitor(figPath, jsonPath, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(np.asarray(trainImages[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(trainImages[0])\n",
    "y = np.asarray(trainLabels[0])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
